{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcY5H7KoQD23NJp9L63//S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joyinning/deep_learning/blob/main/Week_1_Simple_Linear_Regression_in_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Simple Linear Regression with PyTorch"
      ],
      "metadata": {
        "id": "umnzNuaaGP6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code demonstrates how to build and train a simple linear regression model using PyTorch. The goal is to predict a value based on a single input feature, with the underlying relationship being **y = 2x**."
      ],
      "metadata": {
        "id": "WXAMHINWGRMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries\n",
        "1. torch: Prediction\n",
        "torch.no_grad(): disables gradient calculation temporarily\n",
        "A new input (4.0) is passed to the trained model to get the predicted output.\n",
        "2. torch.nn: Offers building blocks for constructing neural networks, including layers, activation functions, and more.\n",
        "3. torch.optim: Provides a variety of optimization algorithms like Stochastic Gradient Descent (SGD) and Adam to update model parameters during training."
      ],
      "metadata": {
        "id": "KT0sDcwe_mVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn # module\n",
        "import torch.optim as optim # Optimization algorithms"
      ],
      "metadata": {
        "id": "kt2yCwRF_94j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Training Data\n",
        "`[[row=feature], [row], [row]]`: 2-dimensional tensor, 3x1 matrix\n"
      ],
      "metadata": {
        "id": "QRDdyPtnADsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor([[1.0], [2.0], [3.0]], dtype=torch.float32)\n",
        "y_train = torch.tensor([[2.0], [4.0], [6.0]], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "eHaJ7pDyAGS9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the Model"
      ],
      "metadata": {
        "id": "Fux1SeGCAJUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the linear regression model\n",
        "1. `nn.Module`: The base class for all neural network modules in PyTorch. Inheriting from this class allows for seamless integration with PyTorch features like GPU computation and automatic differentiation.\n",
        "2. `__init__()`: This constructor initializes the model's components. In this case, it creates a single linear layer (nn.Linear) that takes one input feature and produces one output value.\n",
        "3. forward: Defines the forward pass of the model. It takes input data (x), passes it through the linear layer, and returns the predicted output.\n"
      ],
      "metadata": {
        "id": "xrkjYZehAPrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self): # initialize all parameters in models\n",
        "        super(LinearRegressionModel, self).__init__() # call the parment class (nn.Module) to implement initialization\n",
        "        self.linear = nn.Linear(1, 1) # Create a linear layer with input 1 x output 1  and assign it to self.linear\n",
        "\n",
        "    def forward(self, x): # get input x,  pass it through self.linear and return the result\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "\n",
        "model = LinearRegressionModel()"
      ],
      "metadata": {
        "id": "q67WaTQ4ALU4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Loss Function and Optimizer\n",
        "1. **Loss Function (Mean Squared Error - MSE)**: Quantifies the error between predicted and actual values. In this regression task, MSE is chosen as the loss function.\n",
        "2. **Optimizer (Stochastic Gradient Descent - SGD)**: An algorithm that iteratively updates the model's parameters (weights and biases) to minimize the loss function.\n",
        "3. `model.parameters()`: Retrieves all the trainable parameters (weights and biases) of the model.\n",
        "4. `lr=0.01`: Sets the learning rate, a hyperparameter that controls the magnitude of parameter updates during each optimization step."
      ],
      "metadata": {
        "id": "mum7biSxAxhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "PqSeTx-qA0UB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "4m6uULUYBFBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loop repeatedly processes the training data (`X_train`, `y_train`) for a specified number of epochs (`num_epochs`).\n",
        "0. **Epoch**: An epoch signifies one complete pass through the entire training dataset.\n",
        "1. **Forward Pass**: The model generates predictions (`outputs`) based on the input (`X_train`). The loss is computed by comparing these predictions to the true values (`y_train`).\n",
        "2. **Backward Pass**: PyTorch's `loss.backward()` method automatically calculates the gradients (how much each parameter contributed to the error) of the loss with respect to each parameter.\n",
        "3. **Optimization**: The optimizer uses the calculated gradients to adjust the model's parameters, aiming to reduce the loss. The `optimizer.zero_grad()` function resets the gradients to zero before each update."
      ],
      "metadata": {
        "id": "GKjDyQyjBJUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step() # Using calculated gradient(slope), update model parameters (weights, bias)\n",
        "\n",
        "    if (epoch+1) % 100 == 0: # print loss values in every 100 time\n",
        "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item())) # The index in Python starts 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKBW5Tk3BGLk",
        "outputId": "35ac4003-c1dc-42dc-93c9-61c8d0d22a41"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.0989\n",
            "Epoch [200/1000], Loss: 0.0611\n",
            "Epoch [300/1000], Loss: 0.0378\n",
            "Epoch [400/1000], Loss: 0.0233\n",
            "Epoch [500/1000], Loss: 0.0144\n",
            "Epoch [600/1000], Loss: 0.0089\n",
            "Epoch [700/1000], Loss: 0.0055\n",
            "Epoch [800/1000], Loss: 0.0034\n",
            "Epoch [900/1000], Loss: 0.0021\n",
            "Epoch [1000/1000], Loss: 0.0013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction\n",
        "1. `torch.no_grad():` Temporarily deactivates gradient tracking. This is necessary during prediction because gradients are only used for training.\n",
        "2. A new input is fed into the trained model, and the model produces a prediction based on its learned parameters. The prediction is the model's best estimate of the output given the new input.\n"
      ],
      "metadata": {
        "id": "MQKVw5LYBrse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    predicted = model(torch.tensor([[4.0]], dtype=torch.float32))\n",
        "    print('Predicted value:', predicted.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Co9JW4cB4Ff",
        "outputId": "a035c6d6-4afc-4bed-9d51-b5964e5f15c4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted value: 7.927868366241455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since 2 * 4 = 8, the predicted value of 7.9278... is very close and indicates that the model has learned the relationship well."
      ],
      "metadata": {
        "id": "9Jbswq-oGev8"
      }
    }
  ]
}